# Adversarial-Attacks
Implemented adversarial attacks in Python on pretrained audio, text, and image models using techniques such as FGSM, PGD, Carlini &amp; Wagner (C&amp;W), and targeted word-replacement; measured attack success rates and analyzed model vulnerabilities to guide robustness improvements.
# Contact
For any questions or feedback, feel free to reach out:

Email: rameenbutt990@gmail.com
